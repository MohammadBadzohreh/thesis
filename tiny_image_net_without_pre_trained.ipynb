{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'tf1.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tf1.6 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "from Utils.TinyImageNet_loader import get_tinyimagenet_dataloaders\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from timm.models import swin_transformer\n",
    "import timm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "image_size = 224  # Swin Transformer input image size\n",
    "num_classes = 200  # Tiny ImageNet classes\n",
    "epochs = 100\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Preprocessing transformations\n",
    "tiny_transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(image_size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "tiny_transform_val = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "tiny_transform_test = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Data loaders\n",
    "train_loader, val_loader, test_loader = get_tinyimagenet_dataloaders(\n",
    "    data_dir='../datasets',\n",
    "    transform_train=tiny_transform_train,\n",
    "    transform_val=tiny_transform_val,\n",
    "    transform_test=tiny_transform_test,\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size,\n",
    ")\n",
    "\n",
    "# Define Swin Transformer model\n",
    "class SwinTransformerTinyImageNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SwinTransformerTinyImageNet, self).__init__()\n",
    "        self.backbone = timm.create_model('swin_base_patch4_window7_224', pretrained=False, num_classes=num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# Count the number of parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Function to calculate top-k accuracy\n",
    "def calculate_top_k_accuracy(outputs, labels, k=1):\n",
    "    _, top_k_predictions = outputs.topk(k, dim=1, largest=True, sorted=True)\n",
    "    correct = top_k_predictions.eq(labels.view(-1, 1).expand_as(top_k_predictions))\n",
    "    return correct.sum().item()\n",
    "\n",
    "# Function to calculate top-1, top-3, top-5 accuracies\n",
    "def calculate_accuracies(outputs, labels):\n",
    "    top_1_acc = calculate_top_k_accuracy(outputs, labels, k=1)\n",
    "    top_3_acc = calculate_top_k_accuracy(outputs, labels, k=3)\n",
    "    top_5_acc = calculate_top_k_accuracy(outputs, labels, k=5)\n",
    "    return top_1_acc, top_3_acc, top_5_acc\n",
    "\n",
    "# Training and evaluation loop\n",
    "def train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs, device):\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_samples = 0\n",
    "        top_1_correct = 0\n",
    "        top_3_correct = 0\n",
    "        top_5_correct = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            top_1, top_3, top_5 = calculate_accuracies(outputs, labels)\n",
    "            total_samples += labels.size(0)\n",
    "            top_1_correct += top_1\n",
    "            top_3_correct += top_3\n",
    "            top_5_correct += top_5\n",
    "\n",
    "        train_top1_acc = 100. * top_1_correct / total_samples\n",
    "        train_top3_acc = 100. * top_3_correct / total_samples\n",
    "        train_top5_acc = 100. * top_5_correct / total_samples\n",
    "        print(f\"Epoch {epoch+1} Train Acc (Top-1): {train_top1_acc:.2f}%, Top-3: {train_top3_acc:.2f}%, Top-5: {train_top5_acc:.2f}%\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_samples = 0\n",
    "        top_1_correct = 0\n",
    "        top_3_correct = 0\n",
    "        top_5_correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                top_1, top_3, top_5 = calculate_accuracies(outputs, labels)\n",
    "                total_samples += labels.size(0)\n",
    "                top_1_correct += top_1\n",
    "                top_3_correct += top_3\n",
    "                top_5_correct += top_5\n",
    "\n",
    "        test_top1_acc = 100. * top_1_correct / total_samples\n",
    "        test_top3_acc = 100. * top_3_correct / total_samples\n",
    "        test_top5_acc = 100. * top_5_correct / total_samples\n",
    "        print(f\"Epoch {epoch+1} Test Acc (Top-1): {test_top1_acc:.2f}%, Top-3: {test_top3_acc:.2f}%, Top-5: {test_top5_acc:.2f}%\")\n",
    "\n",
    "        # Save the best model\n",
    "        if test_top1_acc > best_accuracy:\n",
    "            best_accuracy = test_top1_acc\n",
    "            torch.save(model.state_dict(), 'best_swin_transformer.pth')\n",
    "            print(\"Model saved!\")\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f\"Best Test Accuracy (Top-1): {best_accuracy:.2f}%\")\n",
    "    return model\n",
    "\n",
    "# Initialize the model\n",
    "model = SwinTransformerTinyImageNet(num_classes=num_classes).to(device)\n",
    "num_params = count_parameters(model)\n",
    "print(f\"Number of Parameters: {num_params}\")\n",
    "\n",
    "# Define loss function, optimizer, and learning rate scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "# Train and evaluate the model\n",
    "trained_model = train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs, device)\n",
    "\n",
    "# Load the best model and test\n",
    "model.load_state_dict(torch.load('best_swin_transformer.pth'))\n",
    "trained_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'tf1.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tf1.6 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
