{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m.badzohreh\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "  0%|          | 0/1563 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Paths to the Tiny ImageNet dataset\n",
    "TRAIN_DIR = 'tiny-imagenet-200/train'\n",
    "VAL_DIR = 'tiny-imagenet-200/val'\n",
    "WORDS_FILE = 'tiny-imagenet-200/words.txt'\n",
    "WNIDS_FILE = 'tiny-imagenet-200/wnids.txt'\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_CLASSES = 200\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class TinyImageNetDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.le = LabelEncoder()\n",
    "        unique_labels = sorted(set(labels))  # Sort the unique labels\n",
    "        self.le.fit(unique_labels)\n",
    "        self.encoded_labels = self.le.transform(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.encoded_labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "def load_training_data():\n",
    "    data = []\n",
    "    labels = []\n",
    "    class_dirs = sorted(os.listdir(TRAIN_DIR))  # Ensure consistent class order\n",
    "    for wnid in class_dirs:\n",
    "        wnid_dir = os.path.join(TRAIN_DIR, wnid, 'images')\n",
    "        if os.path.isdir(wnid_dir):\n",
    "            image_files = sorted(os.listdir(wnid_dir))  # Ensure consistent image order\n",
    "            for img_file in image_files:\n",
    "                img_path = os.path.join(wnid_dir, img_file)\n",
    "                data.append(img_path)\n",
    "                labels.append(wnid)\n",
    "    return data, labels\n",
    "\n",
    "def load_validation_data():\n",
    "    val_data = []\n",
    "    val_labels = []\n",
    "    annotations_file = os.path.join(VAL_DIR, 'val_annotations.txt')\n",
    "    val_annotations = {}\n",
    "    with open(annotations_file, 'r') as f:\n",
    "        for line in f:\n",
    "            tokens = line.strip().split('\\t')\n",
    "            filename, wnid = tokens[0], tokens[1]\n",
    "            val_annotations[filename] = wnid\n",
    "    images_dir = os.path.join(VAL_DIR, 'images')\n",
    "    image_files = sorted(os.listdir(images_dir))  # Ensure consistent image order\n",
    "    for img_file in image_files:\n",
    "        img_path = os.path.join(images_dir, img_file)\n",
    "        if img_file in val_annotations:\n",
    "            val_data.append(img_path)\n",
    "            val_labels.append(val_annotations[img_file])\n",
    "    return val_data, val_labels\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.480, 0.448, 0.398],\n",
    "                         std=[0.277, 0.269, 0.282])\n",
    "])\n",
    "\n",
    "# Load training data\n",
    "train_data, train_labels = load_training_data()\n",
    "train_dataset = TinyImageNetDataset(train_data, train_labels, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "# Load validation data\n",
    "val_data, val_labels = load_validation_data()\n",
    "\n",
    "# Split validation data into new validation and test sets\n",
    "val_data, test_data, val_labels, test_labels = train_test_split(\n",
    "    val_data, val_labels, test_size=0.5, random_state=42, stratify=val_labels)\n",
    "\n",
    "# Create validation dataset and dataloader\n",
    "val_dataset = TinyImageNetDataset(val_data, val_labels, transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "# Create test dataset and dataloader\n",
    "test_dataset = TinyImageNetDataset(test_data, test_labels, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, img_size=64, patch_size=16, num_classes=NUM_CLASSES, dim=512, depth=6, heads=8, mlp_dim=1024):\n",
    "        super(ViT, self).__init__()\n",
    "        assert img_size % patch_size == 0, \"Image dimensions must be divisible by the patch size.\"\n",
    "        num_patches = (img_size // patch_size) ** 2\n",
    "        patch_dim = 3 * patch_size * patch_size\n",
    "\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        # Linear projection of flattened patches\n",
    "        self.to_patch_embedding = nn.Linear(patch_dim, dim)\n",
    "\n",
    "        # Position embeddings\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "\n",
    "        # Transformer Encoder\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=dim, nhead=heads, dim_feedforward=mlp_dim),\n",
    "            num_layers=depth\n",
    "        )\n",
    "\n",
    "        # Classification head\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        # Divide images into patches\n",
    "        patches = x.unfold(2, self.patch_size, self.patch_size).unfold(3, self.patch_size, self.patch_size)\n",
    "        patches = patches.contiguous().view(B, C, -1, self.patch_size, self.patch_size)\n",
    "        patches = patches.permute(0, 2, 1, 3, 4)\n",
    "        patches = patches.reshape(B, -1, 3 * self.patch_size * self.patch_size)\n",
    "\n",
    "        # Linear embedding\n",
    "        tokens = self.to_patch_embedding(patches)\n",
    "\n",
    "        # Add [CLS] token\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
    "        tokens = torch.cat((cls_tokens, tokens), dim=1)\n",
    "\n",
    "        # Add positional embedding\n",
    "        tokens += self.pos_embedding[:, :tokens.size(1), :]\n",
    "\n",
    "        # Transformer encoding\n",
    "        tokens = tokens.permute(1, 0, 2)  # Required shape for transformer: (S, N, E)\n",
    "        encoded_tokens = self.transformer(tokens)\n",
    "        encoded_tokens = encoded_tokens.permute(1, 0, 2)\n",
    "\n",
    "        # Classification head\n",
    "        cls_token_final = encoded_tokens[:, 0]\n",
    "        out = self.mlp_head(cls_token_final)\n",
    "\n",
    "        return out\n",
    "\n",
    "def accuracy(output, target, topk=(1, 3, 5)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)  # Get indices of top k predictions\n",
    "    pred = pred.t()  # Transpose to shape (k, batch_size)\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))  # Check if predictions are correct\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)  # Count correct predictions\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))  # Compute accuracy percentage\n",
    "    return res\n",
    "\n",
    "def train(model, device, train_loader, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    top1_acc = 0.0\n",
    "    top3_acc = 0.0\n",
    "    top5_acc = 0.0\n",
    "    total = 0\n",
    "\n",
    "    loop = tqdm(train_loader)\n",
    "    for batch_idx, (inputs, targets) in enumerate(loop):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        acc1, acc3, acc5 = accuracy(outputs, targets, topk=(1, 3, 5))\n",
    "        top1_acc += acc1.item()\n",
    "        top3_acc += acc3.item()\n",
    "        top5_acc += acc5.item()\n",
    "        total += 1\n",
    "\n",
    "        # Update tqdm loop\n",
    "        loop.set_description(f\"Epoch [{epoch}/{NUM_EPOCHS}]\")\n",
    "        loop.set_postfix(loss=(running_loss/total), top1_acc=(top1_acc/total), top3_acc=(top3_acc/total), top5_acc=(top5_acc/total))\n",
    "\n",
    "    return running_loss/total, top1_acc/total, top3_acc/total, top5_acc/total\n",
    "\n",
    "def validate(model, device, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    top1_acc = 0.0\n",
    "    top3_acc = 0.0\n",
    "    top5_acc = 0.0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loop = tqdm(val_loader)\n",
    "        for batch_idx, (inputs, targets) in enumerate(loop):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            acc1, acc3, acc5 = accuracy(outputs, targets, topk=(1, 3, 5))\n",
    "            top1_acc += acc1.item()\n",
    "            top3_acc += acc3.item()\n",
    "            top5_acc += acc5.item()\n",
    "            total += 1\n",
    "\n",
    "            # Update tqdm loop\n",
    "            loop.set_description(f\"Validation\")\n",
    "            loop.set_postfix(loss=(running_loss/total), top1_acc=(top1_acc/total), top3_acc=(top3_acc/total), top5_acc=(top5_acc/total))\n",
    "\n",
    "    return running_loss/total, top1_acc/total, top3_acc/total, top5_acc/total\n",
    "\n",
    "def test(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    top1_acc = 0.0\n",
    "    top3_acc = 0.0\n",
    "    top5_acc = 0.0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loop = tqdm(test_loader)\n",
    "        for batch_idx, (inputs, targets) in enumerate(loop):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            acc1, acc3, acc5 = accuracy(outputs, targets, topk=(1, 3, 5))\n",
    "            top1_acc += acc1.item()\n",
    "            top3_acc += acc3.item()\n",
    "            top5_acc += acc5.item()\n",
    "            total += 1\n",
    "\n",
    "            # Update tqdm loop\n",
    "            loop.set_description(f\"Test\")\n",
    "            loop.set_postfix(loss=(running_loss/total), top1_acc=(top1_acc/total), top3_acc=(top3_acc/total), top5_acc=(top5_acc/total))\n",
    "\n",
    "    avg_loss = running_loss / total\n",
    "    avg_top1_acc = top1_acc / total\n",
    "    avg_top3_acc = top3_acc / total\n",
    "    avg_top5_acc = top5_acc / total\n",
    "\n",
    "    print(f\"Test Loss: {avg_loss:.4f}\")\n",
    "    print(f\"Test Acc@1: {avg_top1_acc:.2f}%\")\n",
    "    print(f\"Test Acc@3: {avg_top3_acc:.2f}%\")\n",
    "    print(f\"Test Acc@5: {avg_top5_acc:.2f}%\")\n",
    "\n",
    "    return avg_loss, avg_top1_acc, avg_top3_acc, avg_top5_acc\n",
    "\n",
    "# Initialize model, criterion, and optimizer\n",
    "model = ViT().to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_top1_acc = []\n",
    "val_top1_acc = []\n",
    "train_top3_acc = []\n",
    "val_top3_acc = []\n",
    "train_top5_acc = []\n",
    "val_top5_acc = []\n",
    "\n",
    "best_acc = 0.0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    train_loss, train_acc1, train_acc3, train_acc5 = train(model, DEVICE, train_loader, criterion, optimizer, epoch)\n",
    "    val_loss, val_acc1, val_acc3, val_acc5 = validate(model, DEVICE, val_loader, criterion)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_top1_acc.append(train_acc1)\n",
    "    val_top1_acc.append(val_acc1)\n",
    "    train_top3_acc.append(train_acc3)\n",
    "    val_top3_acc.append(val_acc3)\n",
    "    train_top5_acc.append(train_acc5)\n",
    "    val_top5_acc.append(val_acc5)\n",
    "\n",
    "    # Save the best model\n",
    "    if val_acc1 > best_acc:\n",
    "        best_acc = val_acc1\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f\"Best model saved with accuracy: {best_acc:.2f}%\")\n",
    "\n",
    "    print(f\"Epoch {epoch}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"Train Acc@1: {train_acc1:.2f}%, Val Acc@1: {val_acc1:.2f}%\")\n",
    "    print(f\"Train Acc@3: {train_acc3:.2f}%, Val Acc@3: {val_acc3:.2f}%\")\n",
    "    print(f\"Train Acc@5: {train_acc5:.2f}%, Val Acc@5: {val_acc5:.2f}%\")\n",
    "\n",
    "def plot_metrics(train_metric, val_metric, metric_name):\n",
    "    epochs = range(1, NUM_EPOCHS + 1)\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, train_metric, 'b', label=f'Training {metric_name}')\n",
    "    plt.plot(epochs, val_metric, 'r', label=f'Validation {metric_name}')\n",
    "    plt.title(f'Training and Validation {metric_name}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{metric_name}.png')\n",
    "    plt.show()\n",
    "\n",
    "# Plot Loss\n",
    "plot_metrics(train_losses, val_losses, 'Loss')\n",
    "\n",
    "# Plot Top-1 Accuracy\n",
    "plot_metrics(train_top1_acc, val_top1_acc, 'Top-1 Accuracy')\n",
    "\n",
    "# Plot Top-3 Accuracy\n",
    "plot_metrics(train_top3_acc, val_top3_acc, 'Top-3 Accuracy')\n",
    "\n",
    "# Plot Top-5 Accuracy\n",
    "plot_metrics(train_top5_acc, val_top5_acc, 'Top-5 Accuracy')\n",
    "\n",
    "print(\"Model Parameters:\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name}: {param.data.shape}\")\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc1, test_acc3, test_acc5 = test(model, DEVICE, test_loader, criterion)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cu12.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
