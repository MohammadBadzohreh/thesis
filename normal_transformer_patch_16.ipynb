{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'tiny-imagenet-200/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 99\u001b[0m\n\u001b[0;32m     88\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m     89\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)),\n\u001b[0;32m     90\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mRandomResizedCrop(\u001b[38;5;241m224\u001b[39m, scale\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m1.0\u001b[39m)),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     95\u001b[0m                          std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m])\n\u001b[0;32m     96\u001b[0m ])\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# Load training data\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m train_data, train_labels \u001b[38;5;241m=\u001b[39m \u001b[43mload_training_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m TinyImageNetDataset(train_data, train_labels, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[0;32m    101\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 57\u001b[0m, in \u001b[0;36mload_training_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     56\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 57\u001b[0m class_dirs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTRAIN_DIR\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# Ensure consistent class order\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m wnid \u001b[38;5;129;01min\u001b[39;00m class_dirs:\n\u001b[0;32m     59\u001b[0m     wnid_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(TRAIN_DIR, wnid, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'tiny-imagenet-200/train'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchvision.models import vit_b_16\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# Paths to the Tiny ImageNet dataset\n",
    "TRAIN_DIR = 'tiny-imagenet-200/train'\n",
    "VAL_DIR = 'tiny-imagenet-200/val'\n",
    "WORDS_FILE = 'tiny-imagenet-200/words.txt'\n",
    "WNIDS_FILE = 'tiny-imagenet-200/wnids.txt'\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 128  # Increased batch size\n",
    "NUM_EPOCHS = 50   # Increased number of epochs\n",
    "LEARNING_RATE = 1e-4  # Reduced learning rate\n",
    "NUM_CLASSES = 200\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class TinyImageNetDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.le = LabelEncoder()\n",
    "        unique_labels = sorted(set(labels))  # Sort the unique labels\n",
    "        self.le.fit(unique_labels)\n",
    "        self.encoded_labels = self.le.transform(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.encoded_labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "def load_training_data():\n",
    "    data = []\n",
    "    labels = []\n",
    "    class_dirs = sorted(os.listdir(TRAIN_DIR))  # Ensure consistent class order\n",
    "    for wnid in class_dirs:\n",
    "        wnid_dir = os.path.join(TRAIN_DIR, wnid, 'images')\n",
    "        if os.path.isdir(wnid_dir):\n",
    "            image_files = sorted(os.listdir(wnid_dir))  # Ensure consistent image order\n",
    "            for img_file in image_files:\n",
    "                img_path = os.path.join(wnid_dir, img_file)\n",
    "                data.append(img_path)\n",
    "                labels.append(wnid)\n",
    "    return data, labels\n",
    "\n",
    "def load_validation_data():\n",
    "    val_data = []\n",
    "    val_labels = []\n",
    "    annotations_file = os.path.join(VAL_DIR, 'val_annotations.txt')\n",
    "    val_annotations = {}\n",
    "    with open(annotations_file, 'r') as f:\n",
    "        for line in f:\n",
    "            tokens = line.strip().split('\\t')\n",
    "            filename, wnid = tokens[0], tokens[1]\n",
    "            val_annotations[filename] = wnid\n",
    "    images_dir = os.path.join(VAL_DIR, 'images')\n",
    "    image_files = sorted(os.listdir(images_dir))  # Ensure consistent image order\n",
    "    for img_file in image_files:\n",
    "        img_path = os.path.join(images_dir, img_file)\n",
    "        if img_file in val_annotations:\n",
    "            val_data.append(img_path)\n",
    "            val_labels.append(val_annotations[img_file])\n",
    "    return val_data, val_labels\n",
    "\n",
    "# Updated transform with data augmentation and adjusted image size\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load training data\n",
    "train_data, train_labels = load_training_data()\n",
    "train_dataset = TinyImageNetDataset(train_data, train_labels, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "# Load validation data\n",
    "val_data, val_labels = load_validation_data()\n",
    "\n",
    "# Split validation data into new validation and test sets\n",
    "val_data, test_data, val_labels, test_labels = train_test_split(\n",
    "    val_data, val_labels, test_size=0.5, random_state=42, stratify=val_labels)\n",
    "\n",
    "# Create validation dataset and dataloader\n",
    "val_dataset = TinyImageNetDataset(val_data, val_labels, transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "# Create test dataset and dataloader\n",
    "test_dataset = TinyImageNetDataset(test_data, test_labels, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "# Initialize the pretrained ViT model\n",
    "model = vit_b_16(pretrained=True)\n",
    "model.heads = nn.Linear(model.heads.head.in_features, NUM_CLASSES)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Define loss function with label smoothing\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# Define optimizer with weight decay\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "\n",
    "# Define learning rate scheduler\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "\n",
    "# Initialize GradScaler for mixed precision training\n",
    "scaler = GradScaler()\n",
    "\n",
    "def accuracy(output, target, topk=(1, 3, 5)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)  # Get indices of top k predictions\n",
    "    pred = pred.t()  # Transpose to shape (k, batch_size)\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))  # Check if predictions are correct\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)  # Count correct predictions\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))  # Compute accuracy percentage\n",
    "    return res\n",
    "\n",
    "def train(model, device, train_loader, criterion, optimizer, scheduler, scaler, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    top1_acc = 0.0\n",
    "    top3_acc = 0.0\n",
    "    top5_acc = 0.0\n",
    "    total = 0\n",
    "\n",
    "    loop = tqdm(train_loader)\n",
    "    for batch_idx, (inputs, targets) in enumerate(loop):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        acc1, acc3, acc5 = accuracy(outputs, targets, topk=(1, 3, 5))\n",
    "        top1_acc += acc1.item()\n",
    "        top3_acc += acc3.item()\n",
    "        top5_acc += acc5.item()\n",
    "        total += 1\n",
    "\n",
    "        # Update tqdm loop\n",
    "        loop.set_description(f\"Epoch [{epoch}/{NUM_EPOCHS}]\")\n",
    "        loop.set_postfix(loss=(running_loss/total), top1_acc=(top1_acc/total), top3_acc=(top3_acc/total), top5_acc=(top5_acc/total))\n",
    "\n",
    "    return running_loss/total, top1_acc/total, top3_acc/total, top5_acc/total\n",
    "\n",
    "def validate(model, device, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    top1_acc = 0.0\n",
    "    top3_acc = 0.0\n",
    "    top5_acc = 0.0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loop = tqdm(val_loader)\n",
    "        for batch_idx, (inputs, targets) in enumerate(loop):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            acc1, acc3, acc5 = accuracy(outputs, targets, topk=(1, 3, 5))\n",
    "            top1_acc += acc1.item()\n",
    "            top3_acc += acc3.item()\n",
    "            top5_acc += acc5.item()\n",
    "            total += 1\n",
    "\n",
    "            # Update tqdm loop\n",
    "            loop.set_description(f\"Validation\")\n",
    "            loop.set_postfix(loss=(running_loss/total), top1_acc=(top1_acc/total), top3_acc=(top3_acc/total), top5_acc=(top5_acc/total))\n",
    "\n",
    "    return running_loss/total, top1_acc/total, top3_acc/total, top5_acc/total\n",
    "\n",
    "def test(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    top1_acc = 0.0\n",
    "    top3_acc = 0.0\n",
    "    top5_acc = 0.0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loop = tqdm(test_loader)\n",
    "        for batch_idx, (inputs, targets) in enumerate(loop):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            acc1, acc3, acc5 = accuracy(outputs, targets, topk=(1, 3, 5))\n",
    "            top1_acc += acc1.item()\n",
    "            top3_acc += acc3.item()\n",
    "            top5_acc += acc5.item()\n",
    "            total += 1\n",
    "\n",
    "            # Update tqdm loop\n",
    "            loop.set_description(f\"Test\")\n",
    "            loop.set_postfix(loss=(running_loss/total), top1_acc=(top1_acc/total), top3_acc=(top3_acc/total), top5_acc=(top5_acc/total))\n",
    "\n",
    "    avg_loss = running_loss / total\n",
    "    avg_top1_acc = top1_acc / total\n",
    "    avg_top3_acc = top3_acc / total\n",
    "    avg_top5_acc = top5_acc / total\n",
    "\n",
    "    print(f\"Test Loss: {avg_loss:.4f}\")\n",
    "    print(f\"Test Acc@1: {avg_top1_acc:.2f}%\")\n",
    "    print(f\"Test Acc@3: {avg_top3_acc:.2f}%\")\n",
    "    print(f\"Test Acc@5: {avg_top5_acc:.2f}%\")\n",
    "\n",
    "    return avg_loss, avg_top1_acc, avg_top3_acc, avg_top5_acc\n",
    "\n",
    "def plot_metrics(train_metric, val_metric, metric_name):\n",
    "    epochs = range(1, NUM_EPOCHS + 1)\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, train_metric, 'b', label=f'Training {metric_name}')\n",
    "    plt.plot(epochs, val_metric, 'r', label=f'Validation {metric_name}')\n",
    "    plt.title(f'Training and Validation {metric_name}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{metric_name}.png')\n",
    "    plt.show()\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_top1_acc = []\n",
    "val_top1_acc = []\n",
    "train_top3_acc = []\n",
    "val_top3_acc = []\n",
    "train_top5_acc = []\n",
    "val_top5_acc = []\n",
    "\n",
    "best_acc = 0.0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    train_loss, train_acc1, train_acc3, train_acc5 = train(\n",
    "        model, DEVICE, train_loader, criterion, optimizer, scheduler, scaler, epoch)\n",
    "    val_loss, val_acc1, val_acc3, val_acc5 = validate(\n",
    "        model, DEVICE, val_loader, criterion)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_top1_acc.append(train_acc1)\n",
    "    val_top1_acc.append(val_acc1)\n",
    "    train_top3_acc.append(train_acc3)\n",
    "    val_top3_acc.append(val_acc3)\n",
    "    train_top5_acc.append(train_acc5)\n",
    "    val_top5_acc.append(val_acc5)\n",
    "\n",
    "    # Save the best model\n",
    "    if val_acc1 > best_acc:\n",
    "        best_acc = val_acc1\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f\"Best model saved with accuracy: {best_acc:.2f}%\")\n",
    "\n",
    "    print(f\"Epoch {epoch}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"Train Acc@1: {train_acc1:.2f}%, Val Acc@1: {val_acc1:.2f}%\")\n",
    "    print(f\"Train Acc@3: {train_acc3:.2f}%, Val Acc@3: {val_acc3:.2f}%\")\n",
    "    print(f\"Train Acc@5: {train_acc5:.2f}%, Val Acc@5: {val_acc5:.2f}%\")\n",
    "\n",
    "# Plot Loss\n",
    "plot_metrics(train_losses, val_losses, 'Loss')\n",
    "\n",
    "# Plot Top-1 Accuracy\n",
    "plot_metrics(train_top1_acc, val_top1_acc, 'Top-1 Accuracy')\n",
    "\n",
    "# Plot Top-3 Accuracy\n",
    "plot_metrics(train_top3_acc, val_top3_acc, 'Top-3 Accuracy')\n",
    "\n",
    "# Plot Top-5 Accuracy\n",
    "plot_metrics(train_top5_acc, val_top5_acc, 'Top-5 Accuracy')\n",
    "\n",
    "print(\"Model Parameters:\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name}: {param.data.shape}\")\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc1, test_acc3, test_acc5 = test(model, DEVICE, test_loader, criterion)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cu12.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
