{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '../datasets/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b066f6d5a538>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0mtransform_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtiny_transform_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m     \u001b[0mimage_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m )\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-b066f6d5a538>\u001b[0m in \u001b[0;36mget_tinyimagenet_dataloaders\u001b[1;34m(data_dir, transform_train, transform_val, transform_test, batch_size, image_size)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# Use ImageFolder for dataset loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mtrain_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mval_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mtest_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Mohammad Badzohreh\\anaconda3\\envs\\tf1.6\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[0;32m    311\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m                                           \u001b[0mtarget_transform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m                                           is_valid_file=is_valid_file)\n\u001b[0m\u001b[0;32m    314\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Mohammad Badzohreh\\anaconda3\\envs\\tf1.6\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m    143\u001b[0m         super(DatasetFolder, self).__init__(root, transform=transform,\n\u001b[0;32m    144\u001b[0m                                             target_transform=target_transform)\n\u001b[1;32m--> 145\u001b[1;33m         \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Mohammad Badzohreh\\anaconda3\\envs\\tf1.6\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \"\"\"\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Mohammad Badzohreh\\anaconda3\\envs\\tf1.6\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mSee\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;32mclass\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \"\"\"\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '../datasets/train'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "from Utils.TinyImageNet_loader import get_tinyimagenet_dataloaders\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from timm.models import swin_transformer\n",
    "import timm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "image_size = 224  # Swin Transformer input image size\n",
    "num_classes = 200  # Tiny ImageNet classes\n",
    "epochs = 100\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Function to define data loaders\n",
    "def get_tinyimagenet_dataloaders(data_dir, transform_train, transform_val, transform_test, batch_size, image_size):\n",
    "    train_dir = f\"{data_dir}/train\"\n",
    "    val_dir = f\"{data_dir}/val\"\n",
    "    test_dir = f\"{data_dir}/test\"\n",
    "\n",
    "    # Use ImageFolder for dataset loading\n",
    "    train_dataset = datasets.ImageFolder(root=train_dir, transform=transform_train)\n",
    "    val_dataset = datasets.ImageFolder(root=val_dir, transform=transform_val)\n",
    "    test_dataset = datasets.ImageFolder(root=test_dir, transform=transform_test)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# Preprocessing transformations\n",
    "tiny_transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(image_size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "tiny_transform_val = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "tiny_transform_test = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Dataset directory\n",
    "data_dir = '../datasets'\n",
    "\n",
    "# Data loaders\n",
    "train_loader, val_loader, test_loader = get_tinyimagenet_dataloaders(\n",
    "    data_dir=data_dir,\n",
    "    transform_train=tiny_transform_train,\n",
    "    transform_val=tiny_transform_val,\n",
    "    transform_test=tiny_transform_test,\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size,\n",
    ")\n",
    "\n",
    "# Define Swin Transformer model\n",
    "class SwinTransformerTinyImageNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SwinTransformerTinyImageNet, self).__init__()\n",
    "        self.backbone = timm.create_model('swin_base_patch4_window7_224', pretrained=False, num_classes=num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# Count the number of parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Function to calculate top-k accuracy\n",
    "def calculate_top_k_accuracy(outputs, labels, k=1):\n",
    "    _, top_k_predictions = outputs.topk(k, dim=1, largest=True, sorted=True)\n",
    "    correct = top_k_predictions.eq(labels.view(-1, 1).expand_as(top_k_predictions))\n",
    "    return correct.sum().item()\n",
    "\n",
    "# Function to calculate top-1, top-3, top-5 accuracies\n",
    "def calculate_accuracies(outputs, labels):\n",
    "    top_1_acc = calculate_top_k_accuracy(outputs, labels, k=1)\n",
    "    top_3_acc = calculate_top_k_accuracy(outputs, labels, k=3)\n",
    "    top_5_acc = calculate_top_k_accuracy(outputs, labels, k=5)\n",
    "    return top_1_acc, top_3_acc, top_5_acc\n",
    "\n",
    "# Training and evaluation loop\n",
    "def train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs, device):\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_samples = 0\n",
    "        top_1_correct = 0\n",
    "        top_3_correct = 0\n",
    "        top_5_correct = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            inputs, labels = batch  # Ensure proper unpacking\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            top_1, top_3, top_5 = calculate_accuracies(outputs, labels)\n",
    "            total_samples += labels.size(0)\n",
    "            top_1_correct += top_1\n",
    "            top_3_correct += top_3\n",
    "            top_5_correct += top_5\n",
    "\n",
    "        train_top1_acc = 100. * top_1_correct / total_samples\n",
    "        train_top3_acc = 100. * top_3_correct / total_samples\n",
    "        train_top5_acc = 100. * top_5_correct / total_samples\n",
    "        print(f\"Epoch {epoch+1} Train Acc (Top-1): {train_top1_acc:.2f}%, Top-3: {train_top3_acc:.2f}%, Top-5: {train_top5_acc:.2f}%\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_samples = 0\n",
    "        top_1_correct = 0\n",
    "        top_3_correct = 0\n",
    "        top_5_correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                inputs, labels = batch  # Ensure proper unpacking\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                top_1, top_3, top_5 = calculate_accuracies(outputs, labels)\n",
    "                total_samples += labels.size(0)\n",
    "                top_1_correct += top_1\n",
    "                top_3_correct += top_3\n",
    "                top_5_correct += top_5\n",
    "\n",
    "        test_top1_acc = 100. * top_1_correct / total_samples\n",
    "        test_top3_acc = 100. * top_3_correct / total_samples\n",
    "        test_top5_acc = 100. * top_5_correct / total_samples\n",
    "        print(f\"Epoch {epoch+1} Test Acc (Top-1): {test_top1_acc:.2f}%, Top-3: {test_top3_acc:.2f}%, Top-5: {test_top5_acc:.2f}%\")\n",
    "\n",
    "        # Save the best model\n",
    "        if test_top1_acc > best_accuracy:\n",
    "            best_accuracy = test_top1_acc\n",
    "            torch.save(model.state_dict(), 'best_swin_transformer.pth')\n",
    "            print(\"Model saved!\")\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f\"Best Test Accuracy (Top-1): {best_accuracy:.2f}%\")\n",
    "    return model\n",
    "\n",
    "# Initialize the model\n",
    "model = SwinTransformerTinyImageNet(num_classes=num_classes).to(device)\n",
    "num_params = count_parameters(model)\n",
    "print(f\"Number of Parameters: {num_params}\")\n",
    "\n",
    "# Define loss function, optimizer, and learning rate scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "# Train and evaluate the model\n",
    "trained_model = train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs, device)\n",
    "\n",
    "# Load the best model and test\n",
    "model.load_state_dict(torch.load('best_swin_transformer.pth'))\n",
    "trained_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'tf1.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tf1.6 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
