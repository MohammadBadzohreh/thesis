{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Data augmentation and normalization\n",
    "mean = [0.4802, 0.4481, 0.3975]\n",
    "std = [0.2302, 0.2265, 0.2262]\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(64),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "# Paths to the training and validation directories\n",
    "train_dir = './tiny-imagenet-200/train'\n",
    "val_dir = './tiny-imagenet-200/val/sorted_val'\n",
    "\n",
    "# Get sorted list of class names\n",
    "class_names = sorted(os.listdir(train_dir))\n",
    "\n",
    "# Create a mapping from class names to indices\n",
    "class_to_idx = {cls_name: idx for idx, cls_name in enumerate(class_names)}\n",
    "\n",
    "# Create datasets with sorted class labels\n",
    "trainset = torchvision.datasets.ImageFolder(\n",
    "    root=train_dir,\n",
    "    transform=transform_train,\n",
    "    target_transform=lambda label: class_to_idx[trainset.classes[label]],\n",
    ")\n",
    "\n",
    "valset = torchvision.datasets.ImageFolder(\n",
    "    root=val_dir,\n",
    "    transform=transform_val,\n",
    "    target_transform=lambda label: class_to_idx[valset.classes[label]],\n",
    ")\n",
    "\n",
    "# Data loaders\n",
    "trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4)\n",
    "valloader = DataLoader(valset, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "classes = 200  # Tiny ImageNet has 200 classes\n",
    "\n",
    "# Model Definition\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, img_size=64, patch_size=8, in_channels=3, embed_dim=512):\n",
    "        super().__init__()\n",
    "        self.num_patches = (img_size // patch_size) ** 2\n",
    "        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)  # [batch_size, embed_dim, H', W']\n",
    "        x = x.flatten(2)  # [batch_size, embed_dim, num_patches]\n",
    "        x = x.transpose(1, 2)  # [batch_size, num_patches, embed_dim]\n",
    "        return x\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, embed_dim=512, num_heads=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layer_norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.self_attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout)\n",
    "        self.layer_norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(embed_dim * 4, embed_dim),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_norm = self.layer_norm1(x)\n",
    "        attn_output, _ = self.self_attn(x_norm.transpose(0, 1), x_norm.transpose(0, 1), x_norm.transpose(0, 1))\n",
    "        x = x + attn_output.transpose(0, 1)\n",
    "\n",
    "        x_norm = self.layer_norm2(x)\n",
    "        mlp_output = self.mlp(x_norm)\n",
    "        x = x + mlp_output\n",
    "        return x\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self, img_size=64, patch_size=8, in_channels=3, num_classes=200, embed_dim=512, depth=6, num_heads=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.patch_embed = PatchEmbedding(img_size, patch_size, in_channels, embed_dim)\n",
    "        num_patches = self.patch_embed.num_patches\n",
    "\n",
    "        # Class token\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        # Position embedding\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))\n",
    "        self.pos_drop = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Transformer encoder layers\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerEncoderLayer(embed_dim, num_heads, dropout) for _ in range(depth)\n",
    "        ])\n",
    "\n",
    "        # Classification head\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.head = nn.Linear(embed_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Concatenate class token\n",
    "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "        # Add position embedding\n",
    "        x = x + self.pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "\n",
    "        # Transformer encoder\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        # Classification head\n",
    "        x = self.norm(x)\n",
    "        cls_token_final = x[:, 0]\n",
    "        out = self.head(cls_token_final)\n",
    "        return out\n",
    "\n",
    "# Calculate total number of parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "model = VisionTransformer().to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "total_params = count_parameters(model)\n",
    "print(f'Total number of parameters: {total_params}')\n",
    "\n",
    "# Training Components\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Loss function with label smoothing\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# Optimizer with weight decay\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.05)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "# Accuracy calculation\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)  # Get top k predictions\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res  # Returns list of accuracies\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 100  # Adjust as needed\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    top1_train = []\n",
    "    top3_train = []\n",
    "    top5_train = []\n",
    "\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        acc1, acc3, acc5 = accuracy(outputs, labels, topk=(1, 3, 5))\n",
    "        top1_train.append(acc1.item())\n",
    "        top3_train.append(acc3.item())\n",
    "        top5_train.append(acc5.item())\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    # Average training loss and accuracy\n",
    "    epoch_loss = running_loss / len(trainloader.dataset)\n",
    "    train_acc1 = np.mean(top1_train)\n",
    "    train_acc3 = np.mean(top3_train)\n",
    "    train_acc5 = np.mean(top5_train)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    top1_val = []\n",
    "    top3_val = []\n",
    "    top5_val = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            acc1, acc3, acc5 = accuracy(outputs, labels, topk=(1, 3, 5))\n",
    "            top1_val.append(acc1.item())\n",
    "            top3_val.append(acc3.item())\n",
    "            top5_val.append(acc5.item())\n",
    "\n",
    "    val_acc1 = np.mean(top1_val)\n",
    "    val_acc3 = np.mean(top3_val)\n",
    "    val_acc5 = np.mean(top5_val)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "    print(f'Train Accuracies: Top-1 {train_acc1:.2f}%, Top-3 {train_acc3:.2f}%, Top-5 {train_acc5:.2f}%')\n",
    "    print(f'Val Accuracies:   Top-1 {val_acc1:.2f}%, Top-3 {val_acc3:.2f}%, Top-5 {val_acc5:.2f}%\\n')\n",
    "\n",
    "    # Save the best model\n",
    "    if val_acc1 > best_acc:\n",
    "        best_acc = val_acc1\n",
    "        torch.save(model.state_dict(), 'best_vit_tiny_imagenet.pth')\n",
    "\n",
    "# Reporting Final Results\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_vit_tiny_imagenet.pth'))\n",
    "\n",
    "# Evaluate on the training set\n",
    "model.eval()\n",
    "top1_train = []\n",
    "top3_train = []\n",
    "top5_train = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        acc1, acc3, acc5 = accuracy(outputs, labels, topk=(1, 3, 5))\n",
    "        top1_train.append(acc1.item())\n",
    "        top3_train.append(acc3.item())\n",
    "        top5_train.append(acc5.item())\n",
    "\n",
    "train_acc1 = np.mean(top1_train)\n",
    "train_acc3 = np.mean(top3_train)\n",
    "train_acc5 = np.mean(top5_train)\n",
    "\n",
    "print(f'Final Training Accuracies: Top-1 {train_acc1:.2f}%, Top-3 {train_acc3:.2f}%, Top-5 {train_acc5:.2f}%')\n",
    "\n",
    "# Evaluate on the validation set\n",
    "top1_val = []\n",
    "top3_val = []\n",
    "top5_val = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in valloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        acc1, acc3, acc5 = accuracy(outputs, labels, topk=(1, 3, 5))\n",
    "        top1_val.append(acc1.item())\n",
    "        top3_val.append(acc3.item())\n",
    "        top5_val.append(acc5.item())\n",
    "\n",
    "val_acc1 = np.mean(top1_val)\n",
    "val_acc3 = np.mean(top3_val)\n",
    "val_acc5 = np.mean(top5_val)\n",
    "\n",
    "print(f'Final Validation Accuracies: Top-1 {val_acc1:.2f}%, Top-3 {val_acc3:.2f}%, Top-5 {val_acc5:.2f}%')\n",
    "\n",
    "# Report the number of parameters\n",
    "print(f'Total number of parameters: {total_params}')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
